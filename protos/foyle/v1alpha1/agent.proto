syntax = "proto3";

import "google/protobuf/struct.proto";
import "foyle/v1alpha1/doc.proto";
import "runme/parser/v1/parser.proto";

option go_package = "github.com/jlewi/foyle/protos/go/foyle/v1alpha1";

// grpc-gateway
// https://github.com/grpc-ecosystem/grpc-gateway
import "google/api/annotations.proto";


// IMPORTANT:
// If you update or add any new methods to this file then you need to update
// Server.registerGRPCGatewayRoutes to have gin delegate the appropriate requests to the grpc gateway server.

message GenerateRequest {
  Doc doc = 1;
}

message GenerateResponse {
  repeated Block blocks = 1;
  string trace_id = 2;
}

// Generate completions using AI
service GenerateService {
  // Generate generates new cells given an existing document.
  rpc Generate (GenerateRequest) returns (GenerateResponse) {
    option (google.api.http) = {
      post: "/api/v1alpha1/generate"
      body: "*"
    };
  }
}

message ExecuteRequest {
  Block block = 1;
}

message ExecuteResponse {
  repeated BlockOutput outputs = 1;
}

// Execute code and commands
service ExecuteService {
  // Execute executes a cell in an existing document.
  rpc Execute(ExecuteRequest) returns (ExecuteResponse) {
    option (google.api.http) = {
      post: "/api/v1alpha1/execute"
      body: "*"
    };
  }
}

// TODO(jeremy): Should we rename this? Maybe NotebookAIService? I think it make sense to keep this
// Separate from the GenerateService because the GenerateService is using the Foyle protos; where as this
// uses the RunMe protos.
service AIService {
  // StreamGenerate is a bidirectional streaming RPC for generating completions
  rpc StreamGenerate (stream StreamGenerateRequest) returns (stream StreamGenerateResponse) {}

  // N.B. This is for testing only. Wanted to add a non streaming response which we can use to verify things are working.
  rpc Status(StatusRequest) returns (StatusResponse) {}
}

// TODO(jeremy): We should probably be using RunMe Notebook and Cell protos
// https://github.com/stateful/runme/blob/9658f77dde406abc775fd3f1eb249b5a06e20f4f/pkg/api/proto/runme/ai/v1alpha1/ai.proto#L9
// Because the primary client will be RunMe and we will want to send vscode data structures rather than our own.
message StreamGenerateRequest {
  oneof request {
    FullContext full_context = 1;
    UpdateContext update = 2;
  }
}

message FullContext {
  runme.parser.v1.Notebook notebook = 1;
  // TODO(jeremy): Should we move selected and notebook_uri out of the full_context and into the StreamGenerateRequest?
  int32 selected = 2;
  string notebook_uri = 3;
}

message UpdateContext {
  runme.parser.v1.Cell cell = 1;
}

message Finish {
  // Indicates whether the completion was accepted or rejected.
  bool accepted = 1;
}

message StreamGenerateResponse {  
  repeated runme.parser.v1.Cell cells = 1;

  // Each response should include the information to identify the notebook and cell where it should be inserted.
  // TODO(jeremy): Should we implement some type of optimistic locking so we can check if the notebook has modified
  // in a way that would invalidate the request?

  // The URI of the notebook to which the block belongs.
  string notebook_uri = 3;
  // The cell index at which to insert at
  int32 insert_at = 4;
}

  enum AIServiceStatus {
    UNKNOWN = 0;
    OK = 1;
    NOT_OK = 2;    
  }
  
  message StatusRequest{}
  message StatusResponse {
    AIServiceStatus status = 1;
  }
  